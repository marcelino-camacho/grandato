{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Ingesta de las tablas de la base de datos mediante Sqoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingesta = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if ingesta:\n",
    "    !JAVA_HOME=/usr/lib/jvm/java-7-oracle-cloudera sqoop import \\\n",
    "        --connect jdbc:mysql://10.0.4.201/stacklite \\\n",
    "        --username training \\\n",
    "        --password training \\\n",
    "        --table question_tags \\\n",
    "        --hive-import \\\n",
    "        --hive-table grupo1_question_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if ingesta:\n",
    "    !JAVA_HOME=/usr/lib/jvm/java-7-oracle-cloudera sqoop import \\\n",
    "        --connect jdbc:mysql://10.0.4.201/stacklite \\\n",
    "        --username training \\\n",
    "        --password training \\\n",
    "        --table questions \\\n",
    "        --hive-import \\\n",
    "        --hive-table grupo1_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Carga la tabla de hive en un spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark.stop()\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"Python Spark SQL Hive\")\n",
    "         .config(\"spark.sql.warehouse.dir\", \"/user/hive/warehouse\")\n",
    "         .config(\"hive.metastore.uris\", \"thrift://ip-10-0-4-11.eu-west-1.compute.internal:9083\")\n",
    "         .enableHiveSupport()\n",
    "         .getOrCreate()\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Selección de base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('use default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Carga y fusión de tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_overflow_df = spark.sql(\"select s.tag as tag, t.creation_date as fecha \\\n",
    "                              from grupo1_question_tags s, grupo1_questions t where s.id = t.id\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#stack_overflow_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_overflow_results_path = \"/home/testing86/Proyecto/data/stack_overflow_results/\"\n",
    "numberOfResults = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preparar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Eliminar mes y día de la fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "stack_overflow_df = (stack_overflow_df\n",
    "                       .select(stack_overflow_df.tag, year(stack_overflow_df.fecha).alias('year'))).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Procesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Lista de años y número de tags por año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc, count\n",
    "years_and_tags_counts_df = (stack_overflow_df.groupBy('year')\n",
    "                            .agg(count('tag').alias('numberOfTags'))\n",
    "                            .sort(asc('year'))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_years = years_and_tags_counts_df.select('year').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_tags_counts = years_and_tags_counts_df.select('numberOfTags').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_years_tagsCounts = {}\n",
    "for i in range(len(lista_years)):\n",
    "    dict_years_tagsCounts[lista_years[i]] = lista_tags_counts[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Guardar los resultados a ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_and_tags_counts_filename = 'years_and_tags_counts.csv'\n",
    "years_and_tags_counts_df.toPandas().to_csv(stack_overflow_results_path \n",
    "                                           + years_and_tags_counts_filename, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Top 10 de los tags más populares de cada año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, desc, col, format_number\n",
    "\n",
    "popular_tags_df = []\n",
    "for i in range(len(lista_years)):\n",
    "    popular_tags_df.append(stack_overflow_df\n",
    "                     .filter(stack_overflow_df.year == str(lista_years[i]))\n",
    "                     .groupBy('tag').agg(count('tag').alias('Menciones')).sort(desc('Menciones'))\n",
    "                     .withColumn('Promedio', \n",
    "                                 format_number(col('Menciones')/lista_tags_counts[i] * 100,2).cast('Float')).cache())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Guardar los resultados a ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_csv = 2008\n",
    "\n",
    "for i in range(len(lista_years)):\n",
    "    popular_tags_filename = 'popular_tags_' + str(anno_csv) +'.csv'\n",
    "    popular_tags_df[i].limit(numberOfResults).toPandas().to_csv(stack_overflow_results_path \n",
    "                                          + popular_tags_filename, header=True, index=False)\n",
    "    anno_csv +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Top 10 de los tags más populares del 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_tags_2017 = popular_tags_df[-1].select('tag').rdd.flatMap(lambda x: x).take(numberOfResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Guardar los resultados a ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "popular_tags_2017_filename = 'list_popular_tags_2017.csv'\n",
    "popular_tags_df[-1].select('tag').limit(10).toPandas().to_csv(stack_overflow_results_path \n",
    "                                           + popular_tags_2017_filename, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Extracto de 20000 tags del 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags_20K_2017_filename = 'tags_20K_2017.csv'\n",
    "(stack_overflow_df.filter(stack_overflow_df.year == str(lista_years[-1]))\n",
    " .select('tag').limit(20000).toPandas()\n",
    " .to_csv(stack_overflow_results_path + tags_20K_2017_filename, header=True, index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Evolución histórica de los tags más populares del 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def average_tag_per_year(year, tag_count):\n",
    "    counts_year = dict_years_tagsCounts[year]\n",
    "    return (tag_count/counts_year)*100\n",
    "\n",
    "udf_average_tag_per_year = udf(average_tag_per_year, DoubleType())\n",
    "\n",
    "historical_tags_df = []\n",
    "for i in range(len(popular_tags_2017)):\n",
    "    historical_tags_df.append(stack_overflow_df\n",
    "                 .filter(stack_overflow_df.tag == popular_tags_2017[i])\n",
    "                 .groupBy('year').agg(count('year').alias('Menciones')).sort(asc('year'))\n",
    "                 .withColumn('Promedio', \n",
    "                             format_number(udf_average_tag_per_year('year','Menciones'),2).cast('Float')).cache())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 Guardar los resultados a ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 1\n",
    "\n",
    "for i in range(len(popular_tags_2017)):\n",
    "    popular_tags_2017_historical_filename = 'popular_tags_2017_rank_' + str(rank) +'_historical.csv'\n",
    "    historical_tags_df[i].toPandas().to_csv(stack_overflow_results_path \n",
    "                                          + popular_tags_2017_historical_filename, header=True, index=False)\n",
    "    rank +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
